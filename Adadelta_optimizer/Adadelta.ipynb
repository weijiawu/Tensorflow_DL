{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adadelta\n",
    "Adadelta 算是 Adagrad 法的延伸，它跟 RMSProp 一样，都是为了解决 Adagrad 中学习率不断减小的问题，RMSProp 是通过移动加权平均的方式，而 Adadelta 也是一种方法，有趣的是，它并不需要学习率这个参数。\n",
    "\n",
    "## Adadelta 法\n",
    "Adadelta 跟 RMSProp 一样，先使用移动平均来计算 s\n",
    "\n",
    "$$\n",
    "s = \\rho s + (1 - \\rho) g^2\n",
    "$$\n",
    "\n",
    "这里 $\\rho$ 和 RMSProp 中的 $\\alpha$ 都是移动平均系数，g 是参数的梯度，然后我们会计算需要更新的参数的变化量\n",
    "\n",
    "$$\n",
    "g' = \\frac{\\sqrt{\\Delta \\theta + \\epsilon}}{\\sqrt{s + \\epsilon}} g\n",
    "$$\n",
    "\n",
    "$\\Delta \\theta$ 初始为 0 张量，每一步做如下的指数加权移动平均更新\n",
    "\n",
    "$$\n",
    "\\Delta \\theta = \\rho \\Delta \\theta + (1 - \\rho) g'^2\n",
    "$$\n",
    "\n",
    "最后参数更新如下\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - g'\n",
    "$$\n",
    "\n",
    "下面我们实现以下 Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.layers import hidden_layer, DNN\n",
    "\n",
    "tf.set_random_seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据导入\n",
    "mnist = input_data.read_data_sets('../MNIST_data', one_hot=True)\n",
    "\n",
    "train_set = mnist.train\n",
    "test_set = mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "input_ph = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n",
    "label_ph = tf.placeholder(shape=(None, 10), dtype=tf.int64)\n",
    "\n",
    "dnn = DNN(input_ph, [200], weights_collection='params', biases_collection='params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建`loss`和`acc`\n",
    "loss = tf.losses.softmax_cross_entropy(logits=dnn, onehot_labels=label_ph)\n",
    "\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(dnn, axis=-1), tf.argmax(label_ph, axis=-1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取梯度\n",
    "params = tf.get_collection('params')\n",
    "\n",
    "gradients = tf.gradients(loss, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义`Adadelta`更新算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adadelta_update(params, gradients, sqrs, deltas, rho, name='adadelta_update'):\n",
    "    eps = 1e-6\n",
    "    \n",
    "    update_ops = []\n",
    "    for param, gradient, sqr, delta in zip(params, gradients, sqrs, deltas):\n",
    "        sqr_update = sqr.assign(rho * sqr + (1 - rho) * tf.square(gradient))\n",
    "        with tf.control_dependencies([sqr_update]):\n",
    "            curr_delta = tf.sqrt(delta + eps) / tf.sqrt(sqr + eps) * gradient\n",
    "            delta_update = delta.assign(rho * delta + (1 - rho) * tf.square(gradient))\n",
    "            with tf.control_dependencies([delta_update]):\n",
    "                update_ops.append(param.assign_sub(curr_delta))\n",
    "                \n",
    "    update_op = tf.group(*update_ops, name=name)\n",
    "    return update_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义辅助变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('sqrs'):\n",
    "    for i, param in enumerate(params):\n",
    "        v = tf.get_variable(param.op.name, shape=param.get_shape(), initializer=tf.zeros_initializer(), dtype=tf.float32)\n",
    "        tf.add_to_collection('sqrs', v)\n",
    "\n",
    "with tf.variable_scope('deltas'):\n",
    "    for i, param in enumerate(params):\n",
    "        v = tf.get_variable(param.op.name, shape=param.get_shape(), initializer=tf.zeros_initializer(), dtype=tf.float32)\n",
    "        tf.add_to_collection('deltas', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrs = tf.get_collection('sqrs')\n",
    "deltas = tf.get_collection('deltas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用adadelta定义更新`op`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_op = adadelta_update(params, gradients, sqrs, deltas, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "epoch = 0\n",
    "samples_passed = 0\n",
    "epoch_done = False\n",
    "step = 0\n",
    "\n",
    "_start = time.time()\n",
    "while (epoch < 5):\n",
    "    if samples_passed + batch_size >= mnist.train.num_examples:\n",
    "        this_batch = mnist.train.num_examples - samples_passed\n",
    "        samples_passed = 0\n",
    "        epoch += 1\n",
    "        epoch_done = True\n",
    "    else:\n",
    "        samples_passed += batch_size\n",
    "        this_batch = batch_size\n",
    "        \n",
    "    # 获取 batch_size个训练样本\n",
    "    images, labels = train_set.next_batch(this_batch)\n",
    "    if epoch_done:\n",
    "        # 计算所有训练样本的损失值\n",
    "        train_loss = []\n",
    "        for _ in range(train_set.num_examples // 100):\n",
    "            image, label = train_set.next_batch(100)\n",
    "            loss_train = sess.run(loss, feed_dict={input_ph: image, label_ph: label})\n",
    "            train_loss.append(loss_train)\n",
    "\n",
    "        print('Epoch {} Train loss: {:.6f}'.format(epoch, np.array(train_loss).mean()))\n",
    "        epoch_done = False\n",
    "        \n",
    "    # 每30步记录一次训练误差\n",
    "    if step % 30 == 0:\n",
    "        loss_train = sess.run(loss, feed_dict={input_ph: images, label_ph: labels})\n",
    "        train_losses.append(loss_train)\n",
    "        \n",
    "    sess.run(update_op, feed_dict={input_ph: images, label_ph: labels})\n",
    "    step += 1\n",
    "\n",
    "_end = time.time()\n",
    "print('Train Done! Cost Time: {:.2f}s'.format(_end - _start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.linspace(0, 5, len(train_losses), endpoint=True)\n",
    "plt.semilogy(x_axis, train_losses, label='adadelta')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train.AdadeltaOptimizer\n",
    "`tensorflow`中也集成了`Adadelta`方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdadeltaOptimizer(learning_rate=1.0, rho=0.9).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_losses1 = []\n",
    "\n",
    "epoch = 0\n",
    "samples_passed = 0\n",
    "epoch_done = False\n",
    "step = 0\n",
    "\n",
    "_start = time.time()\n",
    "while (epoch < 5):\n",
    "    if samples_passed + batch_size >= mnist.train.num_examples:\n",
    "        this_batch = mnist.train.num_examples - samples_passed\n",
    "        samples_passed = 0\n",
    "        epoch += 1\n",
    "        epoch_done = True\n",
    "    else:\n",
    "        samples_passed += batch_size\n",
    "        this_batch = batch_size\n",
    "        \n",
    "    # 获取 batch_size个训练样本\n",
    "    images, labels = train_set.next_batch(this_batch)\n",
    "    if epoch_done:\n",
    "        # 计算所有训练样本的损失值\n",
    "        train_loss = []\n",
    "        for _ in range(train_set.num_examples // 100):\n",
    "            image, label = train_set.next_batch(100)\n",
    "            loss_train = sess.run(loss, feed_dict={input_ph: image, label_ph: label})\n",
    "            train_loss.append(loss_train)\n",
    "\n",
    "        print('Epoch {} Train loss: {:.6f}'.format(epoch, np.array(train_loss).mean()))\n",
    "        epoch_done = False\n",
    "        \n",
    "    # 每30步记录一次训练误差\n",
    "    if step % 30 == 0:\n",
    "        loss_train = sess.run(loss, feed_dict={input_ph: images, label_ph: labels})\n",
    "        train_losses1.append(loss_train)\n",
    "        \n",
    "    sess.run(train_op, feed_dict={input_ph: images, label_ph: labels})\n",
    "    step += 1\n",
    "\n",
    "_end = time.time()\n",
    "print('Train Done! Cost Time: {:.2f}s'.format(_end - _start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
