{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过神经网络预测房价\n",
    "在这个项目中，我们希望能够构建神经网络来预测房屋的价格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们导入一些必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取训练集和测试集的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/train.csv')\n",
    "test = pd.read_csv('./dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以具体看看前面 5 个训练集长什么样子，可以看到，前面都是这个房屋的属性，最后是房屋的价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着我们可以看看训练集和测试集分别有多少个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('一共有 {} 个训练集样本'.format(train.shape[0]))\n",
    "print('一共有 {} 个测试集样本'.format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着我们开始对数据进行处理，首先我们取出**第二个特征**到**倒数第二个特征**，这些特征作为我们神经网络的输入特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat((train.loc[:, 'MSSubClass':'SaleCondition'],\n",
    "                          test.loc[:, 'MSSubClass':'SaleCondition']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着我们需要进行数据标准化，对于所有的数值特征，我们都会减去均值，除以方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = all_features.dtypes[all_features.dtypes != \"object\"].index # 取出所有的数值特征\n",
    "\n",
    "# 减去均值，除以方差\n",
    "all_features[numeric_feats] = all_features[numeric_feats].apply(lambda x: (x - x.mean()) \n",
    "                                                                / (x.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你仔细看看上面的特征，你会发现，除了数值特征之外，还有很多非数值特征，这些特征我们没有办法将其转换成数值表示，所以我们通过 pandas 的内置函数将其转换成种类表示\n",
    "\n",
    "比如 **MSZoning** 有两种可能，一种是 RL，一种是 RM，那么我们就将这个特征变成两个新的特征，RL 和 RM，如果这个数据在 **MSZoning** 上是 RL，那么 RL 取 1，RM 取 0；反之如果这个特征是 RM，那么 RL 取 0，RM 取 1.\n",
    "\n",
    "| RL | RM |\n",
    "|-|-|\n",
    "| 0 | 1 |\n",
    "| 1 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.get_dummies(all_features, dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除此之外，我们会发现整个数据中有一些丢失数据，这些丢失数据都是 'NA'，我们没有办法将这些数据输入到网络中，所以需要对这些丢失数据进行赋值，这里我们将数据的均值填入到丢失数据中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = all_features.fillna(all_features.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们已经做好了数据的预处理，下面我们将所有的训练集和验证集都取出成为一个 numpy 的数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = train.shape[0]\n",
    "\n",
    "train_features = all_features[:num_train].as_matrix().astype(np.float32)\n",
    "test_features = all_features[num_train:].as_matrix().astype(np.float32)\n",
    "\n",
    "train_labels = train.SalePrice.as_matrix()[:, None].astype(np.float32)\n",
    "test_labels = test.SalePrice.as_matrix()[:, None].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面需要你来填写代码完成本次的项目\n",
    "\n",
    "**注意：你只需要完成下面 todo 的部分**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们需要构造容纳输入和输出的占位符, 之后我们一直填入元素即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ph = tf.placeholder(tf.float32, (None, 331), name='input_ph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 构造接收 label 的占位符\n",
    "\n",
    "label_ph = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造神经网络\n",
    "\n",
    "接下来我们开始构造神经网络, 可以像课程中构造一些基本的单元快速搭建(例如我们用过`from nets import DNN`), \n",
    "\n",
    "也可以试着自己独立构造符合自己使用习惯的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(inputs, scope='model', reuse=None):\n",
    "    '''构造模型函数\n",
    "    \n",
    "    参数:\n",
    "      inputs: 2维输入tensor.\n",
    "      scope: 默认参数域.\n",
    "      reuse: 是否重用参数域内的参数\n",
    "      \n",
    "    返回:\n",
    "      net: 网络输出\n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        #TODO\n",
    "        # 构造神经网络\n",
    "        net = None\n",
    "        \n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with slim.arg_scope([slim.fully_connected], \n",
    "                    activation_fn=tf.nn.relu, \n",
    "                    weights_regularizer=slim.regularizers.l2_regularizer(0.0005)):\n",
    "    y_ = model(input_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以调整的超参\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 100\n",
    "use_gpu = False\n",
    "lr = 0.1\n",
    "weight_decay = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 mse 作为 loss 函数\n",
    "\n",
    "使用 Tensorflow 可以从最基本的 op 中定义 mse, 也可以调用`tf.losses`模块中预先定义好的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 构造 mse 形式的 loss 函数\n",
    "mse = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造优化方法\n",
    "我们需要定义模型参数的更新规则, 也就是优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 生成一个优化器, 可以从 tf.train 里面寻找\n",
    "opt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 使用优化器生成一个训练 op\n",
    "train_op = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里, 我们定义一个数据迭代器, 帮助训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_data(x, y, batch_size=50, shuffle=False):\n",
    "    indices = range(x.shape[0])\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    ind = 0\n",
    "    while (ind + batch_size <= x.shape[0]):\n",
    "        batch_x = x[indices[ind: ind + batch_size], :]\n",
    "        batch_y = y[indices[ind: ind + batch_size], :]\n",
    "        ind += batch_size\n",
    "        \n",
    "        yield batch_x, batch_y\n",
    "        \n",
    "    if ind < x.shape[0]:\n",
    "        batch_x = x[ind:, :]\n",
    "        batch_y = y[ind:, :]\n",
    "        \n",
    "        yield batch_x, batch_y\n",
    "    else:\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在评估模型的时候，为了保证大的价格和小的价格对模型都有着近似相同的影响，我们不会直接使用前面定义的均方误差作为最后的评价函数，我们会对预测的价格和真实的价格取 log，然后计算他们之间均方误差的平方根来作为评价指标，这里的指标我们已经在 `utils.py` 中实现了，感兴趣的同学可以去看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_rmse_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造训练函数\n",
    "\n",
    "接下来将下面函数中 **TODO** 的部分完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_ph, label_ph, pred_op, train_op, \n",
    "                    x_train, y_train, x_valid, y_valid, epochs):\n",
    "    metric_log = dict()\n",
    "    metric_log['train_loss'] = list()\n",
    "    if x_valid is not None:\n",
    "        metric_log['valid_loss'] = list()\n",
    "    \n",
    "    #TODO\n",
    "    # 开启一个 Session\n",
    "    sess = None\n",
    "    \n",
    "    #TODO\n",
    "    # 对所有参数进行初始化\n",
    "    pass\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        train_data = get_data(x_train, y_train, batch_size, True)\n",
    "        if x_valid is not None:\n",
    "            valid_data = get_data(x_valid, y_valid, batch_size, False)\n",
    "        else:\n",
    "            valid_data = None\n",
    "            \n",
    "        # 训练模型\n",
    "        for data in train_data:\n",
    "            x, y = data\n",
    "            #TODO\n",
    "            # 使用 session 运行 train_op\n",
    "            pass\n",
    "            \n",
    "        # 测试训练集\n",
    "        train_data = get_data(x_train, y_train, batch_size, False)\n",
    "        pred_train = list()\n",
    "        for x, _ in train_data:\n",
    "            #TODO\n",
    "            # 使用 session 运行 pred_op\n",
    "            pred = None\n",
    "            pred_train.append(pred)\n",
    "        \n",
    "        pred_train = np.concatenate(pred_train, axis=0)\n",
    "        metric_log['train_loss'].append(get_rmse_log(pred_train, y_train))\n",
    "        \n",
    "        # 测试验证集\n",
    "        if x_valid is not None:\n",
    "            valid_data = get_data(x_valid, y_valid, batch_size, False)\n",
    "            pred_valid = list()\n",
    "            for x, _ in valid_data:\n",
    "                #TODO\n",
    "                # 使用 session 运行 pred_op\n",
    "                pred = None\n",
    "                pred_valid.append(pred)\n",
    "\n",
    "            pred_valid = np.concatenate(pred_valid, axis=0)\n",
    "            metric_log['valid_loss'].append(get_rmse_log(pred_valid, y_valid))\n",
    "            \n",
    "            print_str = 'epoch: {}, train loss: {:.3f}, valid loss: {:.3f}'\\\n",
    "            .format(e+1, metric_log['train_loss'][-1], metric_log['valid_loss'][-1])\n",
    "        else:\n",
    "            print_str = 'epoch: {}, train loss: {:.3f}'.format(e+1, metric_log['train_loss'][-1])\n",
    "        if (e + 1) % 10 == 0:\n",
    "            print(print_str)\n",
    "            print()\n",
    "            \n",
    "    sess.close()\n",
    "\n",
    "    # =======不要修改这里的内容========\n",
    "    # 可视化\n",
    "    figsize = (10, 5)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.plot(metric_log['train_loss'], color='red', label='train')\n",
    "    if valid_data is not None:\n",
    "        plt.plot(metric_log['valid_loss'], color='blue', label='valid')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    \n",
    "    return metric_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_log = train_model(input_ph, label_ph, y_, train_op, train_features, train_labels, test_features, test_labels, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
